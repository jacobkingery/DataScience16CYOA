{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import crime\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 884262 entries, 0 to 884261\n",
      "Data columns (total 14 columns):\n",
      "Id            884262 non-null int64\n",
      "Dates         884262 non-null object\n",
      "DayOfWeek     884262 non-null object\n",
      "PdDistrict    884262 non-null object\n",
      "Address       884262 non-null object\n",
      "X             884262 non-null float64\n",
      "Y             884262 non-null float64\n",
      "Year          884262 non-null int64\n",
      "Month         884262 non-null int64\n",
      "Day           884262 non-null int64\n",
      "Hour          884262 non-null int64\n",
      "Minute        884262 non-null int64\n",
      "DoW           884262 non-null int64\n",
      "PdD           884262 non-null int64\n",
      "dtypes: float64(2), int64(8), object(4)\n",
      "memory usage: 101.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train = crime.load_cleaned_train()\n",
    "test = crime.load_cleaned_test()\n",
    "\n",
    "train.columns\n",
    "# print train.info()\n",
    "print test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is cleaned as described in `crime.py`.  In short, Year, Month, Day, Hour, and Minute columns are created, DayOfWeek, PdDistrict, and Category are encoded as integers, and invalid X and Y values are set to the median for that crime's PdDistrict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Split Train Data for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['X', 'Y', 'Year', 'Month', 'Hour', 'DoW', 'PdD']\n",
    "X = train[predictors]\n",
    "y = train.CategoryNumber\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `stratify` parameter of `train_test_split` requires scikit-learn-0.17, but ensures that the proportion of categories is maintained in the split.  The biggest thing that this does is make it so that we always get at least one crime from each category in the training set.  k-NN can only predict based on what it has seen before, so it is crucial that we train the model with all possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we've chosen is the k-Nearest Neighbors model.  For some reason, it is having issues with the fact that there are duplicate data points ---- actually its because there are null Y values....V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3167679703291171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = KNeighborsClassifier(n_neighbors=50, n_jobs=-1)\n",
    "alg.fit(X_train, y_train)\n",
    "\n",
    "p = alg.predict_proba(X_test)\n",
    "crime.logloss(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6596192092540711"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = LogisticRegression()\n",
    "alg.fit(X_train,y_train)\n",
    "\n",
    "p = alg.predict_proba(X_test)\n",
    "crime.logloss(y_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6276539353166206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)\n",
    "alg.fit(X_train,y_train)\n",
    "\n",
    "p = alg.predict_proba(X_test)\n",
    "crime.logloss(y_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6956344784492186"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = GradientBoostingClassifier(random_state=1, n_estimators=10, max_depth=3)\n",
    "alg.fit(X_train,y_train)\n",
    "\n",
    "p = alg.predict_proba(X_test)\n",
    "crime.logloss(y_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.68898640645883"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "gnb = BernoulliNB()\n",
    "y_pred = gnb.fit(X_test, y_test).predict_proba(X_train)\n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "#        % (X_test.shape[0],(y_train != y_pred).sum()))\n",
    "\n",
    "crime.logloss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 7, max_depth = 7, max_leaf_nodes = 20)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "p = clf.predict_proba(X_test)\n",
    "crime.logloss(y_test,p)\n",
    "\n",
    "#let's make a submission\n",
    "crime.create_submission(clf, X, y, test, predictors, 'v1_RFC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFC = 2.57091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
